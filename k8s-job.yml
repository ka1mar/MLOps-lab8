apiVersion: batch/v1
kind: Job
metadata:
  name: clustering-job
  namespace: foodfacts
spec:
  backoffLimit: 3
  ttlSecondsAfterFinished: 3600
  template:
    spec:
      securityContext:
        runAsUser: 1001
      initContainers:
      - name: wait-for-mysql-data
        image: mysql:8.0
        env:
          - name: MYSQL_ROOT_PASSWORD
            valueFrom:
              secretKeyRef:
                name: app-secrets
                key: MYSQL_ROOT_PASSWORD
        command: ["/bin/sh", "-c"]
        args:
        - |
          echo "Waiting for MySQL to be ready with data..."
          until mysql -h mysql -u root -p"$MYSQL_ROOT_PASSWORD" -D foodfacts -e "SELECT COUNT(*) FROM products LIMIT 1" 2>/dev/null; do
            echo "MySQL or data not ready, waiting..."
            sleep 10
          done
          echo "MySQL is ready with data!"
      containers:
      - name: clustering-app
        image: clustering-app:latest
        imagePullPolicy: Never
        env:
          - name: HADOOP_USER_NAME
            value: sparkuser 
          - name: HADOOP_HOME
            value: /home/sparkuser
          - name: SPARK_HOME
            value: /opt/bitnami/spark
          - name: HOME
            value: /home/sparkuser
          - name: SPARK_LOCAL_DIR
            value: /tmp
          - name: MYSQL_URL
            valueFrom:
              configMapKeyRef:
                name: app-config
                key: MYSQL_URL
          - name: MYSQL_USER
            valueFrom:
              secretKeyRef:
                name: app-secrets
                key: MYSQL_USER
          - name: MYSQL_PASSWORD
            valueFrom:
              secretKeyRef:
                name: app-secrets
                key: MYSQL_PASSWORD
          - name: SPARK_DRIVER_MEMORY
            valueFrom:
              configMapKeyRef:
                name: app-config
                key: SPARK_DRIVER_MEMORY
          - name: SPARK_EXECUTOR_MEMORY
            valueFrom:
              configMapKeyRef:
                name: app-config
                key: SPARK_EXECUTOR_MEMORY
          - name: SPARK_EXECUTOR_CORES
            valueFrom:
              configMapKeyRef:
                name: app-config
                key: SPARK_EXECUTOR_CORES
          - name: SPARK_DEFAULT_PARALLELISM
            valueFrom:
              configMapKeyRef:
                name: app-config
                key: SPARK_DEFAULT_PARALLELISM
          - name: SPARK_SQL_SHUFFLE_PARTITIONS
            valueFrom:
              configMapKeyRef:
                name: app-config
                key: SPARK_SQL_SHUFFLE_PARTITIONS
        volumeMounts:
        - name: data-volume
          mountPath: /app/data
        resources:
          requests:
            memory: "2Gi"
            cpu: "1"
          limits:
            memory: "4Gi"
            cpu: "2"
        command: ["/bin/sh", "-c"]
        args:
          - |
            chmod +x /app/scripts/clustering.py
            spark-submit \
            --master local[*] \
            --jars /app/jars/datamart.jar,/app/jars/mysql-connector-java-8.0.33.jar \
            --packages com.mysql:mysql-connector-j:8.0.33 \
            --conf spark.local.dir=/tmp \
            --conf spark.jars.ivy=/tmp/.ivy \
            --conf spark.executor.memory=2g \
            --conf spark.driver.memory=2g \
            /app/scripts/clustering.py \
            --input_table products \
            --output_table predicts \
            -o /app/data/cluster_results \
            --max_missing 0.3 \
            --min_unique 0.001 \
            -v
      volumes:
      - name: data-volume
        persistentVolumeClaim:
          claimName: app-data-pvc
      restartPolicy: Never


